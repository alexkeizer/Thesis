\documentclass[titlepage]{report}

%
%   PACKAGES   
%

\usepackage{illcmolthesis}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{unicode-math}
\usepackage{verbatim}   % for the comment environment
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{xcolor}
\usepackage{framed}

% 
%   Minted
% 

\usepackage[outputdir=./out]{minted}

% instruct minted to use our local theorem.py
\newmintinline[leanm]{lean4.py:Lean4Lexer -x}{fontsize=\small}
\newminted[leancode]{lean4.py:Lean4Lexer -x}{fontsize=\small}

% Lean code that does not typecheck/compile
\newminted[badleancode]{lean4.py:Lean4Lexer -x}{%
    fontsize=\small,%
    frame=leftline,%
    framesep=0mm,%
    rulecolor=red%
}

% Disable the red boxed minted will put around "syntax errors" 
\AtBeginEnvironment{minted}{%
  \renewcommand{\fcolorbox}[4][]{#4}}




%   
%   Fonts & coloring
% 

\usepackage[utf8]{inputenc}
\usepackage{newunicodechar}
\usepackage{fontspec}



% switch to a monospace font supporting more Unicode characters
\setmonofont{JetBrains Mono NL Light}
% \setmonofont{Droid Sans Mono}

\newfontfamily{\freemono}{FreeMono}
\newfontfamily{\droidmono}{Droid Sans Mono}
\newfontfamily{\jbmono}{JetBrains Mono NL Light}


% Colors
\definecolor{keywordcolor}{HTML}{008000}
\definecolor{operatorcolor}{HTML}{008000}

% Unicode glyphs

\newcommand\leanoperator[1]{%
\ifx\leanmode\undefined%
#1%
\else%
{\color{operatorcolor} #1}%
\fi%
}
\newcommand\leanmathoperator[1]{\ensuremath{\leanoperator{#1}}} 
\newunicodechar{→}{\leanmathoperator{\rightarrow}}
\newunicodechar{⟹}{\leanmathoperator{\Longrightarrow}}
\newunicodechar{⋅}{\leanmathoperator{\cdot}}

\newunicodechar{α}{{\droidmono α}}
\newunicodechar{β}{{\droidmono β}}
\newunicodechar{γ}{{\droidmono γ}}
\newunicodechar{₁}{\ensuremath{_\text{1}}}
\newunicodechar{₂}{\ensuremath{_\text{2}}}
\newunicodechar{ᵢ}{\ensuremath{_\text{i}}}
\newunicodechar{ⱼ}{\ensuremath{_\text{j}}}
\newunicodechar{ₖ}{\ensuremath{_\text{k}}}
\newunicodechar{ₙ}{\ensuremath{_\text{n}}}
\newunicodechar{ₘ}{\ensuremath{_\text{m}}}
\newunicodechar{₋}{\ensuremath{_\text{-}}}

% 
% \usepackage[GreekAndCoptic]{ucharclasses}
% \setTransitions{GreekAndCoptic}{}{}


% 
%   Spacing & Layout
% 

\usepackage{geometry}

\geometry{
    hmargin=10em
}
\frenchspacing
\setlength{\parskip}{6pt}
\setlength{\parindent}{0pt}



% 
%   Custom environments
% 
\definecolor{shadecolor}{HTML}{F8E0E0}

% definitions
\newenvironment{definition}[1][Definition:]{\begin{trivlist}                         
    \item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
    
% remark    
% \newenvironment{remark}{\begin{trivlist}                         
%   \item[\hskip \labelsep {\bfseries Remark:}]}{\end{trivlist}}



\newenvironment{remark}{%
% \def\FrameCommand{\colorbox{remarkcolor}}%
% \MakeFramed{\advance\hsize-\width \FrameRestore}%
\begin{framed}
\begin{trivlist}
    \item[\hskip \labelsep {\bfseries Remark:}]}%
{%
\end{trivlist}%
\end{framed}
    % \endMakeFramed%
}
    

% todo
\newenvironment{todo}{%
\definecolor{shadecolor}{HTML}{F8E0E0}%
\begin{shaded}%
\begin{trivlist}                         
    \item[\hskip \labelsep {\bfseries Todo:}]}{\end{trivlist}\end{shaded}}

% hidden code    
\newenvironment{leanhidden}{\expandafter\comment}{\expandafter\endcomment}



% 
%   Custom commands
% 

\newcommand\lean[1]{%
\ifx\leanmode\undefined%
\def\leanmode{1}%
\texttt{\small #1}%
\undef\leanmode%%
\else%
\texttt{#1}%
\fi%
}

\newcommand\keyword[1]{{\color{keywordcolor} \textbf{\lean{#1}}}}

\newcommand\inductive{{\keyword{inductive}}}
\newcommand\data{\keyword{data}}
\newcommand\codata{\keyword{codata}}
\newcommand\ldef{\keyword{def}}

\newcommand\Type{\leanm{Type}}
\newcommand\Typen[1]{\leanm{Type #1}}


\begin{document}

%
%   TITLE PAGE
%
\title{TITLE OF THE THESIS}
\author{Alex C.\,Keizer}
\birthdate{October 15th, 1998}
\birthplace{Alkmaar, The Netherlands}
\defensedate{T.B.D, 2022}
\supervisor{Dr Jasmin Blanchette}
\supervisor{Dr Benno van der Berg}
\committeemember{T.B.D.}
% \committeemember{Prof Dr Jane Williams}
% \committeemember{Dr Jill Jones}
% \committeemember{Dr Albert Heijn}
\maketitle

\pagenumbering{roman}

\chapter*{Abstract}
\begin{todo}
    Abstract
\end{todo}

\tableofcontents


\begin{leanhidden}
    import Qpf.Macro

    namespace Thesis
\end{leanhidden}

%
%   TEXT
%
\chapter{Introduction}
\label{ch:intro}
\pagenumbering{arabic}

Modern logic is primarily built on a framework of induction.
It is no surprise, then, that Lean -- an interactive theorem prover / dependently typed, functional programming language -- prominently features induction.
Specifically, it is based on the ``Calculus of Inductive Constructions''.\cite{avigadTheoremProvingLean}

In Lean, new datatypes are defined using the \inductive{} keyword, which exposes a high-level, definitional syntax.

\begin{leancode}
    inductive List α 
    | nil  : List α
    | cons : α → List α → List α
\end{leancode}

Read as follows: \lean{List} has two \emph{constructors}, i.e., ways to construct a list.
\lean{List.nil} is a constant
representing the empty list; 
\lean{List.cons head tail}, where \lean{head} is of type \lean{α} and \lean{tail} is another list, represents the operation of adding a new element to the front of an existing list. Notice also that \lean{α} is a type parameter, meaning that the list is generic over the type its elements; \lean{List Nat} is a list of natural numbers, while \lean{List String} is a list of strings.

From this description, the datatype is freely generated, as codified by the characteristic principles that are automatically added by the \inductive{} command.
The \emph{principle of no confusion} states that different combinations of constructors yield distinct elements of the inductive type, and the \emph{recursion principle} embodies structural recursion on that type. For instance, the following is a simplified signature of a recursion principle for lists:
\begin{center}
    \lean{rec : β → (α → β → β) → (List α → β)}
\end{center}
Where the function \lean{rec b f} maps \lean{List.nil} to the constant \lean{b}, and \lean{List.cons head tail} to \lean{f head (f tail)}. Since Lean is dependently typed, the actual recursion principle is a bit more involved, but the core idea is the same.
This principle also asserts that \lean{List.nil} and \lean{List.cons} are the only ways to obtain elements of type \lean{List}. This extra assertion is also sometimes presented separately as the \emph{principle of no junk}.


The inductive interpretation means that every element of \lean{List} consists of only
finitely many applications of its constructors. In particular, it is not possible
to construct a list with an infinite chain of \text{cons} applications
%LEANIGNORE
\begin{center}
    \lean{cons 0 (cons 1 (cons 2 (cons 3 (cons 4 ( cons 5 ... )))))}
\end{center}
The recursion must end in \lean{nil} at some point, \lean{List} represent only finite lists.
That being said, (countably) infinite lists (also called streams) have a straightforward encoding in Lean, as functions from natural numbers to the parameter type.
\begin{leancode}
    def Stream α := Nat → α
\end{leancode}

The type of potentially infinite lists is simply the sum of \lean{List} and \lean{Stream}.
\begin{leancode}
    inductive CoList α
    | fin : List α      -- a finite list, or
    | inf : Stream α    -- an infinite list
\end{leancode}

However, Lean lacks a comprehensive, definitional solution to defining infinite data structures.
The main contribution of this thesis is the description, and prototype implementation, of \data{} and \codata{} macros, enabling users to write a specification with the familiar syntax of \inductive{}, to define data- and codatatypes based on the theory of \emph{quotients of polynomial functors} \cite{avigadDataTypesQuotients2019a}. Crucially, it allows for codatatypes, with a \emph{coinductive} interpretation.
For example, the following is automatically compiled into types for infinite lists and potentially infinite lists, just like the ad-hoc definitions we saw above.

\begin{leancode}
    codata Stream α
    | cons : α → CoList α → CoList α 

    codata CoList α 
    | nil  : CoList α
    | cons : α → CoList α → CoList α
\end{leancode}

A key observation is that datatypes are generally \emph{functorial}, and even part of certain restricted classes of functors.
This dates back to an effort to add a definitional package for (co)datatypes to Isabelle/HOL (a different theorem prover), based on \emph{bounded natural functors} \cite{biendarraDefiningCoDatatypes,traytelCategoryTheoryBased}.
Avigad et al. established how the theory and fundamental constructions translate to Lean's dependent type system, using the slightly different notion of quotients of polynomial functors (QPF), and provided a formalization of these constructions in Lean 3 \cite{avigadDataTypesQuotients2019a}. This formalization forms the basis of our implementation, after being ported to Lean 4.

The approach we follow is \emph{compositional}:
The \data{} and \codata{} macros will recognize when the newly defined (co)datatype is itself a QPF, and automatically register it as such, enabling its use in subsequent (co)datatype definitions. To wit, (co)datatypes may be defined with a nested mix of induction and coinduction.

For example, the following defines a potentially infinitely branching (because children of a node are stored in a \lean{CoList}) tree of finite depth (because of the inductive interpretation of \data).

\begin{leancode}
    data RoseTree α
    | node : α → CoList (RoseTree α) → RoseTree α
\end{leancode}

Similarly, a finitely branching tree of infinite depth can be defined, assuming \lean{List'} is a QPF version of \lean{List}.
\begin{leanhidden}
    data List' α -- equivalent to List, but using data so it is a QPF
    | nil  : List' α
    | cons : α → List' α
\end{leanhidden}
\begin{leancode}
    codata RoseTree2 α β
    | node : α → List' (RoseTree α) → RoseTree α
\end{leancode}


The implementation is not complete yet, and in particular, doesn't yet generate nicely encapsulated no confusion and (co)recursion principles.
The QPF framework certainly allows for these principles to be derived, and it is already possible to define (co)recursive functions on (co)datatypes.
However, only by invoking the fundamental operation, exposing the supposedly internal QPF encoding. 

A mayor opportunity for future work lies in improving this situation, bringing the experience of writing (co)recursive for \data{} and \codata{} types closer to the equational approach used to define recursive functions for standard \inductive{} types.


\subsection*{Organization}
\Cref{ch:background} will explain what QPFs are, and illustrate Lean's syntax in the process.
\Cref{ch:porting} will dig into the differences between Lean 3 and Lean 4, and detail the process of porting the QPF formalizations made by Avigad et al.
\Cref{ch:enhancing} will describe enhancements made to the formalizations in the process, which go beyond just porting the existing behaviour.
\Cref{ch:procedure} will establish the procedure to translate the definitional syntax of \data{} and \codata{} into the proper constructions in the theory of QPFs.
\Cref{ch:implementing} will go into technical detail about the (proof of concept)
implementation of these macros, and the Lean 4 meta-programming system.
\Cref{ch:limitations} will discuss the limitations of the current implementation, and opportunities for improvement.
Finally, \cref{ch:conclusion} concludes the thesis.

Accompanying code can be found at \url{https://github.com/alexkeizer/qpf4}, it provides the \data{} and \codata{} commands discussed so far, alongside a \lean{qpf} command and \lean{fin\_destr} tactic.

The code snippets in this thesis are tested with version \lean{leanprover/lean4:nightly-2022-04-28}. The same version was used to develop the code in the linked repository.
The thesis also contains code that (intentionally) does not typecheck. These snippets are typeset with a red line, like so:
\begin{badleancode}

    def Foo := Bar -- whoops, Bar does not exist

\end{badleancode}









\chapter{Background}
\label{ch:background}

A key concept for the rest of this thesis will be QPF (Quotient of Polynomial Functor), and how we can use them to encode (co)inductive types. The current chapter serves to illuminate this notion, and explain relevant parts of the Lean system along the way.

We will assume as little background knowledge as possible, yet, some (minimal) exposure to category theory and functional programming concepts will be beneficial to understanding. Readers can find references at \cite{awodeyCategoryTheory2010, milewskiCategoryTheoryProgrammers} for category theory and \cite{christiansenFunctionalProgrammingLean} for functional programming.

% \begin{todo}
%     Add references for FP, maybe The Little Typer?
% \end{todo}

\begin{remark}
    We will use remarks like this one below code snippets to explain Lean syntax and concepts that might not be familiar. We don't assume any knowledge of Lean, but the interested reader is invited to consult the online documentation, or ``Functional Programming in Lean'' for a more comprehensive introduction
    \cite{avigadTheoremProvingLean,christiansenFunctionalProgrammingLean}.
\end{remark}



The encoding of types as QPFs relies on a key observation; a lot of types are functorial in nature.
Take, for example, the inductive type of lists, specified as
\begin{leancode}
    inductive List (α : Type)
    | nil  : List α
    | cons : α → List α → List α
\end{leancode}

This defines a function \lean{List} that takes a type, α, and returns a new type, whose elements represent lists of α.
We call such functions \emph{type functions}. Note that we mean function here in a very concrete sense.

\section{Types are Terms \& Type Universes}
In a dependently typed language, such as Lean, types \emph{are} terms. In particular, things like \lean{Nat} and \lean{String} are types, but they are also \emph{values} of type \Type.
The signature of \lean{List}, then, is \leanm{Type → Type}, just like the signature of, e.g., \lean{Nat.add} (binary addition of natural numbers) is \leanm{Nat → Nat → Nat}.

\begin{remark}
    We also write \leanm{f : α → β} to say ``\lean{f} has type \leanm{α → β}'', meaning that \lean{f} is a function from type \lean{α} to type \lean{β}.
\end{remark}

We call \Type{} a \emph{type universe}, i.e., a type whose elements are themselves types. However, \Type{} is again also a value, which needs be of some type.
It cannot be the case that \leanm{Type : Type}; this leads to Girard's paradox, which is the type theory analogue of Russel's Paradox \cite{girardInterpretationFonctionelleElimination1972}.

Instead, there Lean has an infinite sequence of increasing type universes, so that \leanm{Type : Type 1}, \leanm{Type 1 : Type 2}, and in general, \leanm{Type u : Type (u+1)}. In fact, \leanm{Type} is just a shorthand for \leanm{Type 0}, the smallest type universe.

Universe levels \lean{u} are essentially natural numbers, but they are \textbf{not} first class values, and are indeed very different from elements of \leanm{Nat}.
In particular, when writing \Typen{u}, the universe \lean{u} is \textbf{not} a regular term. There is a separate grammar, with some minimal builtin operations, that defines valid universe levels.

It is possible, and indeed common to be generic over the universe of some type parameter. For example, the actual, \emph{universe polymorphic} definition of lists specifies that the parameter \lean{α} should live in \lean{Type u}.
\begin{leancode}
    inductive List (α : Type u)
    | nil  : List α
    | cons : α → List α → List α
\end{leancode}

Then the signature of \lean{List} becomes \leanm{Type u → Type u}, for any universe level \lean{u}.

\section{Functoriality of type functions}

Returning to our discussion of \lean{List}, there is also an obvious mapping function that lifts a function \lean{f : α → β}, for arbitrary types \lean{α} and \lean{β}, to a function \lean{List α → List β}, by applying \lean{f} to each element of the argument list. Its signature is written as:
\begin{center}
    \leanm{map : (f : α → β) → List α → List β}
\end{center}

\begin{remark}
    If a function takes multiple arguments, it is idiomatic to write them in a \emph{curried} style,
    so \leanm{f : α → β → γ} says that \lean{f} is a function that takes two arguments, an \lean{α} and a \lean{β}, to produce a \lean{γ}. Arrows are right-associative.

    Furthermore, \leanm{(a : α) → β} is a \emph{dependent} arrow; it is a function from \lean{α} to \lean{β}, with the possibility to make the resulting type depend on the \emph{value} \lean{a} of the first argument. 
    We used this syntax in the definition of \lean{map} above, even though it is a regular, non-dependent function, just to give a name to the first argument. 
    It would have been equivalent to write \leanm{map : (α → β) → List α → List β}.

    Notice also that, as \lean{α} and \lean{β} range over all types, they are thus actually also arguments to \lean{map}. Since the value of \lean{α} and \lean{β} can be inferred from the other arguments, though, there is no need to supply values for them when calling \lean{map}, hence, they can be implicit arguments. 
    
    It is possible to explicitly define implicit arguments, using curly brackets \lean{\{...\}}.
    \begin{center}
    \leanm{map: {α β : Type u} → (α → β) → List α → List β}
    \end{center}
    However, Lean will automatically add such implicit binders for free variables, so long as it can infer which type it should have --- this feature is called ``auto bound implicits''. 
    We generally won't write these implicit binders, instead adopting the convention that \lean{α} and \lean{β} refer to types.
\end{remark}

Together, a type function \leanm{F : Type u → Type v} and a mapping operation \lean{map : (f: α → β) → F α → F β} form a \emph{functor}, so long as they preserve: 
\begin{itemize}
    \item \emph{Identity maps}, that is, \lean{F (id α) = id (F α)}, with \lean{id β} the identity function on arbitrary types \lean{β}, and
    \item \emph{Compositions}, that is, \lean{(map f) ∘ (map g) = map (f ∘ g)}, where \lean{∘} denotes function composition
\end{itemize}
\lean{List α} is an example of a functor, but so are, e.g., products (\lean{α × β}) and sums 
(\lean{α ⊕ β}).

A function \lean{f : F α → α}, for some fixed type \lean{α}, is called an \emph{\lean{F}-algebra}; inductive types correspond to an \emph{initial} such algebra. To clarify, an \lean{F}-algebra \lean{f} is initial, if for every \lean{F}-algebra \lean{g} there is exactly one arrow \lean{rec} that makes the square of \cref{fig:initial_alg_square} commute.
\begin{figure}[h]
\begin{todo}
    initial algebra commuting square
\end{todo}

\caption{Commuting square for initial $F$-algebras $f : F(α) → α$}
\label{fig:initial_alg_square}
\end{figure}

Consider the type of natural numbers, \lean{Nat}; we'll show that the constructors for \lean{Nat} 
Consider a functor ${F_{nat}(α) = \lean{Unit} \mathop{⊕} α}$, where \lean{Unit} is the unit type --- with \lean{unit} as its sole inhabitant --- and \lean{⊕} denotes a sum (disjoint union). On functions $f : α → β$, the obvious choice of mapping operation $F(f) : F(α) → F(β)$ is such that $F(f)(\lean{unit}) = \lean{unit}$ and $F(f)(a) = f(a)$ for all $a : α$.

Natural numbers are defined by the constant $0 ∈ \mathbb{N}$ and the function $succ : \mathbb{N} → \mathbb{N}$. Together, these constructors give an algebra $f : F_{nat}(\mathbb{N}) → \mathbb{N}$. 

Let $g : F_{nat}(α) → α$ be an arbitrary $F$-algebra, and define a function $\mathrm{rec} : \mathbb{N} → α$ such that $\mathrm{rec}(0) = g(\lean{unit})$ and  $\mathrm{rec}(n+1) = \mathrm{rec}(g(n))$, for every $n ∈ \mathbb{N}$.

The inductive properties of \lean{Nat} are exactly what makes this algebra initial.

Dually, there is a connection between coinductive types and final coalgebras.
Not all functors, though, have initial algebras, or final coalgebras.
% And, it is not, in general, easy to construct such (co)algebras.


\section{Polynomial functors}
Of special interest are \emph{polynomial functors}, which, intuitively, can be composed from a few primitive operations (such as constants, sums, products and exponentials).
More formally, we say that a polynomial functor is defined by a set $A$ and an $A$-indexed family of sets $B_a$ as
\[
    P(X) = \Sigma_{a ∈ A} B_a \rightarrow X  
\]
That is, $P(X)$ is the disjoint union of all functions from $B_a$ to $X$, for every $a ∈ A$.
In the theory, we generally still refer to functors that are not defined in this form, but are isomorphic to a polynomial functor in the strict sense, as polynomial.

To encode this in Lean, we replace ``set'' with ``type'' and obtain the following.
\footnote{To remain consistent, we will use Lean 4 syntax and naming conventions throughout the whole thesis, even though we are still discussing the formalizations as established by Avigad et al here. The difference with the Lean definitions presented in this chapter, and those presented in their original work are superficial.}
\begin{leancode}
    structure PFunctor := (A : Type) (B : A → Type)
\end{leancode}

\begin{remark}
    \leanm{structure} is a simple wrapper around \inductive, for when there is only one constructor.
    The above is equivalent to
    \begin{leancode}
        inductive PFunctor 
        | mk : (A : Type) → (B : A → Type) → PFunctor
    \end{leancode}
\end{remark}

Then, the operations on types and functions are straightforward
\begin{leancode}
    /-- Applying `P` to an object of `Type` -/
    def PFunctor.Obj (P : PFunctor) (α : Type)
        := Σ x : P.A, P.B x → α

    /-- Applying `P` to a morphism of `Type` -/
    def PFunctor.map (P : PFunctor) (f : α → β) : P.Obj α → P.Obj β 
        := fun ⟨a, g⟩ => ⟨a, f ∘ g⟩
\end{leancode}

\begin{remark}
    Variable \lean{P} is known to be of type \lean{PFunctor}, so \lean{P.Obj} is recognized as \lean{PFunctor.Obj P}. Similarly, as \lean{PFunctor} has only one constructor, \lean{PFunctor.mk}, the anonymous constructor syntax \lean{⟨a, g⟩} is translated to \lean{PFunctor.mk a g}.
    Finally, \leanm{fun ⟨a, g⟩ => _} defines a function that takes a single argument \lean{x : P.Obj α}, and immediately deconstructs it into the constituent elements \lean{a : P.A} and \lean{g : P.B a → α}.
\end{remark}

So an element of \lean{P.Obj α} is a (dependent) pair of a \emph{shape} $a ∈ A$ and a function $g : B_a \rightarrow \alpha$, representing the \emph{contents}. A mapped function \lean{P.map f} then leaves the shape as is, and precomposes $f$ with the content $g$.

\subsection*{W-types}
We already saw that inductive types are freely generated by the constructors. In a sense, an element of, e.g., \lean{Nat} is a well-founded (i.e., finite) tree with two kinds of nodes: \lean{zero} nodes are leaves, and \lean{succ} nodes have exactly one child.

The \emph{W-type} of a polynomial functor \lean{P} is the type of exactly such trees: shapes $a ∈ A$ distinguish different kind of nodes, and the cardinality of $B_a$ determines the number of children nodes of type $a$ have. Such trees are easily encoded by an \inductive{} type.

\begin{leancode}
    inductive W (P : PFunctor)
    | mk (a : P.A) (f : P.B a → W P) : W P
\end{leancode}

By construction, the W-type is the initial algebra of \lean{P}.

It is important to make a distinction between types that \emph{are} polynomial functor, and types that are (equivalent to) W-types \emph{of} polynomial functors. 
For example, \lean{Nat} is not a polynomial functor, but it \emph{is} the W-type of a polynomial functor (namely, \lean{F$_\lean{nat}$}). 

Conversely, \lean{List} is both. It is a polynomial functor: take $A = \mathbb{N}$ and $B_n = \{0,..,n-1\}$, then a list of $n$ elements is encoded as a pair with shape $n$, and content $f : \{0,..,n-i\}$ mapping each $i < n$ to the $i$-th element of the list. 
Simultaneously, \lean{List α}, for every \lean{α} is also the W-type of a \emph{different} polynomial functor, defined by $A = \texttt{Unit} ⊕ α$, where $B$ of the unit value is the empty type and $B_a = \lean{Unit}$ for every $a : α$. The W-type of this polynomial functor consists of trees where leaves represent the empty list, and internal nodes are labelled with an element of type \lean{α} (the head of the list) and have exactly one subtree (the tail of the list).

\subsection*{M-types}
Coinductive types are similar, except that the trees they are represented by may be of infinite depth. Encoding these in Lean is quite a bit more involved.

An \emph{M-type} of a polynomial functor \lean{P} is the type of potentially infinite depth trees, where shapes $a ∈ A$ distinguish different kind of nodes, and the cardinality of $B_a$ determines the number of children nodes of type $a$ have.

An \emph{approximation} of an M-type up to depth $n$ is the type of such trees of height at most $n$, where any required subtrees at depth $n+1$ are replaced with a special ``continue'' leaf. 

\begin{leancode}
  inductive MApprox (P : PFunctor) : Nat → Type u
  | continu : MApprox 0
  | intro {n} : (a : P.A) → (P.B a → MAprrox P n) → MAprrox P (succ n)
\end{leancode}

Then, we define what it means for approximations \emph{agree} --- either the first approximation must be a ``continue'' leaf, or both approximations have nodes of the same kind as root, and the corresponding subtrees recursively agree --- whence an M-type is just an infinite series of approximations of increasing depth where every approximation agrees with the next.

\begin{leancode}
  inductive Agree : ∀ {n : Nat}, MApprox P n → MApprox P (n + 1) → Prop
  | continu (x : MApprox P 0) (y : MApprox P 1) : Agree x y
  | intro {n} {a}   (x  : F.B a → MApprox P n) 
                    (x' : F.B a → MApprox P (n + 1)) 
                    : (∀ i : F.B a, Agree (x i) (x' i))
                    → Agree (MApprox.intro a x) (MApprox.intro a x')

  structure M := 
    (approx : ∀ n, MApprox P n) (consistent : ∀ n, Agree (approx n) (approx (n+1)))
\end{leancode}

The M-type of a polynomial functor is, by construction, its final coalgebra.

\begin{todo}
    % \subsection*{Fixpoints}      

    Clarify fixpoints?

    Recall that (co)inductive types are represented by initial algebras and final coalgebras. The M and W-types of a polynomial functor are exactly such (co)algebras. Thus, defining a polynomial functor also defines a freely generated inductive and coinductive type.

\end{todo}

\section{Quotients}
Lean does not just have \inductive{} types, it also supports quotients of types. For example, it is common to define a multiset as the quotient of lists through the relation that equates lists up to permutation.

%LEANIGNORE
\begin{leancode}
    /-- `List.perm as bs` holds iff `as` is a permutation of `bs` -/
    def List.perm : List α → List α → Prop

    def Multiset α := Quot (@List.perm α)
\end{leancode}

This presents a problem, since quotients cannot be represented by just polynomial functors. Thus, generalize to \emph{quotients} of polynomial functors.

Intuitively, a functor \lean{F} is the quotient of some polynomial functor \lean{P} when, for every \lean{α}, there is a surjective \emph{natural transformation} \lean{abs} from \lean{P.Obj α} to \lean{F α}. We can think of \lean{abs} as mapping abstract objects in \lean{F α} to their concrete representations in \lean{P.Obj α}.

Recall that every functor \lean{F} is equipped with a mapping operation \lean{map} on functions \lean{f : α → β}. To say that \lean{abs} is a natural transformation is to say that it respects this functorial structure. That is to say, the following square should commute:
\begin{todo}
    Commuting square: (see .tex source)

    P α -- P.map f --> P β
     |                  |
     | abs α            | abs β
     |                  |
     \/                 \/
    F α -- map\_F f --> F β 

\end{todo}

Formally, we can show that \lean{abs} is surjective by providing, for every \lean{α}, a function \lean{repr: F α → P.Obj α} and proving that it is a right-inverse.
This is specified in Lean with the \lean{QPF} typeclass.
\begin{leancode}
  class Qpf (F : Type → Type) [Functor F] where
    P        : PFunctor
    abs      : ∀ {α}, P.Obj α → F α
    repr     : ∀ {α}, F α → P.Obj α
    abs_repr : ∀ {α} (x : F α), abs (repr x) = x
    abs_map  : ∀ {α β} (f : α → β) (p : P.Obj α), 
                    abs (f <$> p) = f <$> abs p
\end{leancode}
Where \lean{f <\$> x} is Lean syntax for applying \lean{map$_\texttt{G}$ f} to \lean{x} --- the functor \lean{G} is inferred from the type of \lean{x}.


\subsection*{Compositionality}

This thesis is mostly focussed on (co)datatypes, we don't provide any facilities to help with defining QPF-based quotient types. 
Still, we do maintain full compositionality, even more so than Lean's native notions of \inductive{} and quotient types.

For example, recall the \lean{Multiset} quotient type. One might want to use it to define the type of well-founded, unordered trees.
\begin{badleancode}
  inductive UnorderedTree α
  | node : α → Multiset (UnorderedTree α) → UnorderedTree α
\end{badleancode}

Lean rejects this; it is not allowed to nest recursive occurences of \lean{UnorderedTree} behind a quotient type.

On the other hand, if we (manually) define \lean{Multiset} as a QPF with the same semantics, then we can freely compose it in (co)datatype specifications.
\begin{leancode}
  data UnorderedTree α
  | node : α → Multiset (UnorderedTree α) → UnorderedTree α
\end{leancode}


\begin{todo}
    \begin{itemize}
        \item Multiset example
        \item Impossible with pfunctor
        \item Show QPF definition (univariate, without universes)
        \item Note that we don't specifically look at quotients in the rest of the thesis, but we do do \data{} and \codata{} constructions as QPFs, which compose well. Still, the current implementation breaks when trying to use quotients. (reference limitations section)
    \end{itemize}
\end{todo}











\section{Type Universes}
\label{sec:bg:universes}

A big strength of Lean is that it treats types as first class. Just like \lean{0} is a value of type \lean{Nat}, the type \lean{Nat} is itself a \emph{value}, of type \Type{} (the ``type of types''). Because types are also values, \Type{} needs a type to live in as well. Setting \leanm{(Type: Type)} would lead to unsoundness, so instead, there is a notion of \emph{type universes}. We have that \leanm{Type : Type 1}, \leanm{Type 1 : Type 2}, and in general, \leanm{Type u : Type (u+1)}. In fact, \leanm{Type} is just a shorthand for \leanm{Type 0}, the smallest type universe.

Universe levels are essentially natural numbers, but they are \textbf{not} first class values, and are indeed very different from elements of \leanm{Nat}.
In particular, when writing \Typen{u}, the universe \lean{u} is \textbf{not} a normal term, there is a separate grammar, with some minimal builtin operations, that defines valid universe levels.

We \emph{can} make our definitions generic over which universe to work in, this is called \emph{universe polymorphism}. The polymorphic definition of a polynomial functor looks like
\begin{leancode}
    universe u

    structure PFunctor := (A : Type u) (B : A → Type u)
\end{leancode}
Where the first command declares that \lean{u} is a universe variable in subsequent definitions.
When referring to \lean{PFunctor}, we can specify a universe to work in by writing \lean{PFunctor.\{u\}}. A similar syntax also introduces a universe variable that is local to a single definition.

\begin{leancode}
    def PFunctor.Obj.{v} (P : PFunctor.{v}) (α : Type v)
        := Σ x : P.A, P.B x → α
\end{leancode}

Note that usually we don't have to be this explicit. Lean will usually infer the right universe levels, when left unspecified.
For example, with \lean{map} as before, Lean recognizes that (with the new definition of \lean{PFunctor}) the implicit arguments \lean{α} and \lean{β} live in \Typen{u} and that \lean{P} is a \lean{PFunctor.\{u\}}, for some universe variable \lean{u}.
\begin{leancode}
    def PFunctor.map (P : PFunctor) (f : α → β) : P.Obj α → P.Obj β 
        := fun ⟨a, g⟩ => ⟨a, f ∘ g⟩    
\end{leancode}

The other constructions are easily made universe polymorphic as well.








\section{Multivariate Functors}
\label{sec:mvfunctor}

Earlier, we mentioned that sums and products (written as \lean{α ⊕ β} and \lean{α × β}, respectively, in Lean) are functorial in both arguments.
They are, in fact, polynomial, but, both take two types as arguments and don't fit in the definitions presented so far. We have to generalize from the univariate case to \emph{multivariate} functors.

It is difficult to reason about $n$-ary curried functions, where $n$ is arbitrary, so instead we use the following, \emph{uncurried} representation of multivariate, universe polymorphic, type functions.

\begin{leancode}
    def TypeFun (n : Nat) := (TypeVec.{u} n) → Type v
\end{leancode}
Where \lean{TypeVec} is a \emph{type vector}, i.e., a list of exactly $n$ elements of \Typen{u}.
We define such vectors as a map from a canonical finite type \lean{Fin2 n}, which has exactly $n$ inhabitants.
\begin{leancode}
    def TypeVec (n : Nat) := (i : Fin2 n) → Type u
\end{leancode}
Notice that all arguments to a \lean{TypeFun} live in the same universe $u$, and the result lives in a potentially different universe $v$. 
Most constructions do require that these universes coincide, and use \lean{TypeFun.\{u,u\}}.

Suppose that \lean{Sum'} is the uncurried version of sums, then we would write \lean{Sum' ![α₁, α₂]} to use it with argument types α₁ and α₂ The \lean{map} operation now takes not one function, but a vector (i.e., list of known size) of $n$ functions, each going from \lean{αᵢ} to \lean{βᵢ}. The type of such vectors of functions is written, e.g, \lean{![α₁, α₂] ⟹ ![β₁, β₂]} (when $n=2$).

\begin{leancode}
    map : {v₁ v₂ : TypeVec n} → (v₁ ⟹ v₂) → F v₁ → F v₂
\end{leancode}
\begin{remark}
    Objects of type \lean{TypeVec n}, for some fixed but arbitrary length $n$, and morphisms \leanm{(⋅ ⟹ ⋅)} form a category. 
    Multivariate type functors are in fact nothing more than (univariate) functors on this category of type vectors.
\end{remark}

Thus, if \lean{f₁ : α₁ → β₁} and \lean{f₂ : α₂ → β₂}, then \lean{Sum'.map ![f₁, f₂]} yields a function from \lean{Sum' ![α₁, α₂]} to \lean{Sum' ![β₁, β₂]}.
The functoriality constraints have an obvious generalization to the multivariate case.

\subsection{Multivariate Polynomial Functors}
An $n$-ary, polynomial functor is still defined with a shape $A$ as before, but the content now maps $a ∈ A$ not to a single type, but to a vector of $n$ types.

\begin{leancode}
    structure MvPFunctor (n : Nat) := (A : Type u) (B : A → TypeVec.{u} n)
\end{leancode}

The generalization proceeds relatively straightforwardly.
\begin{leancode}
    def MvPFunctor.Obj (P : MvPFunctor.{u} n) : TypeFun.{u,u} n
        := fun (α : TypeVec n) => Σ a : P.A, P.B a ⟹ α

    def MvPFunctor.map  (P : MvPFunctor.{u} n) 
                        (f : v₀ ⟹ v₁) 
                            : P.Obj v₀ → P.Obj v₁ 
        := fun ⟨a, g⟩ => ⟨a, TypeVec.comp f g⟩
\end{leancode}

Where \lean{TypeVec.comp} is the pointwise composition of two vectors of functions.

\begin{remark}
    Implicit variables are not limited to types, we will use \lean{n} and \lean{m} for natural numbers and \lean{v₀, v₁, ...} for type vectors.
\end{remark}

The generalization of M and W-types to the multivariate case is left as an exercise for the reader.

\subsection{Multivariate QPFs}

\begin{todo}
    List the full definition of MvQpf with universes
\end{todo}


\section{Inductive Families}
\label{sec:ind_families}

It is important to clarify that we're only considering inductive \emph{types}, 
for which the recursive occurrences of the type being declared must not use other values for the type parameters. Lean also has inductive \emph{families} of types for which this restriction does not hold.

Consider, for example, \lean{Fin2}, the type of natural numbers less than $n$.
\begin{badleancode}
    inductive BadFin2 (n : Nat)
    | fz : BadFin2 (n+1)
    | fs : BadFin2 n → BadFin2 (n+1)
\end{badleancode}

This won't compile, because this defines an inductive type, and the constructors mention \lean{BadFin2 (n+1)}, while they are only allowed to mention \lean{BadFin2 n}.

The syntax for an inductive family is very similar; we can promote \lean{n} from parameter to \emph{index} by removing the binder, and giving a type signature.

\begin{leancode}
    inductive Fin2 : Nat → Type
    | fz : Fin2 (n+1)
    | fs : Fin2 n → Fin2 (n+1)
\end{leancode}

Inductive families do not correspond to initial algebras in the same way that inductive types do, and the constructions as QPFs \emph{fundamentally} don't support inductive families, nor the coinductive analogue.
Hence, we shall limit ourselves to just (co)inductive types.




\chapter{Porting the QPF formalization from Lean3 to Lean4}
\label{ch:porting}


\begin{todo}
    Porting
    \begin{itemize}
        \item Mention Lean3 -> Lean4 differences (instability)
        \item Mention mathlib3 -> mathlib4 (mention that qpfs are part of mathlib3)
        \item Mathport 
                \begin{itemize}
                    \item Takes care of syntactic differences, different naming conventions (mostly)
                    \item Proofs did not translate well (a lot of tactics were missing)
                \end{itemize}
        \item \url{https://leanprover.zulipchat.com/#narrow/stream/287929-mathlib4/topic/mathport.3A.20cases_on.20.3D.3E.20casesOn}
            \begin{itemize}
                \item Implicit \lean{motive} arguments were being inferred differently
                \item \lean{set\_option pp.analyze true}
            \end{itemize}
    \end{itemize}
\end{todo}




%LEAN namespace Enhancing
\chapter{Enhancing the QPF formalization}
\label{ch:enhancing}


In the preceding chapter we presented the formalization of QPFs as made by Avigad et al. In the process of porting the code from Lean3 to Lean4, various enhancements were identified, and indeed implemented. 

These chapter serves to elaborate on these changes to the existing behaviour which are too big to be considered just porting, but don't fall strictly under (co)datatype synthesis and metaprogramming parts of the project.






\section{Functions \& Currying}
Like most functional languages, in Lean it is idiomatic to write functions in their curried form, 
so \leanm{f : Type → Type → Type}, rather than \leanm{f : (Type × Type) → Type}.
However, the formalizations are done in terms of uncurried type functions.

%LEAN namespace Hidden -- hide definition, so it does not interfere
\begin{leancode}
    def TypeFun (n : Nat)
      := TypeVec n → Type v
\end{leancode}
%LEAN end Hidden

Which is a function that takes a list of exactly $n$ types, and returns a type --- the \lean{u} and
\lean{v} refer to the respective universes that these types live in, and betray a technical limitation
of this encoding: all arguments to a \leanm{TypeFun} must live in the same universe.

There is an obvious translation from \leanm{TypeFun} to a curried type function and, vice versa, from a curried function taking $n$ types from the same universe and returning a type, to a \leanm{TypeFun n}.
These conversions were implemented as \leanm{TypeFun.toCurried} and \leanm{TypeFun.ofCurried}, respectively, and it was proven that these functions are isomorphisms. 

To wit, they function as expected:
\begin{leancode}
    variable (F : TypeFun 2) (F' : Type 1 → Type 1 → Type 2)
    example : F.curried α β = F ![α, β]                 := by rfl
    example : F' α β = (TypeFun.ofCurried F') ![α, β]   := by rfl
\end{leancode}

The type \leanm{CurriedFun α β n} is a recursively defined alias for \leanm{α → ... → α → β}, taking $n$ arguments of type \lean{α} to produce an element of \lean{β}.
\begin{leancode}
    abbrev CurriedFun (α : Type u) (β : Type v) : Nat → Type (max u v)
      | 0   => PUnit.{u+1} → β
      | 1   => α → β
      | n+1 => α → CurriedFun α β n
\end{leancode}
Intuitively one might expect a \leanm{CurriedFun} taking no arguments (so, $n = 0$) to be equal to  just \leanm{β}, but that does not typecheck --- \leanm{Type v} and \leanm{Type (max u v)} are not, in general, the same type.
One should be able to lift \lean{β} into the right universe, but such functions are not particularly interesting, so the simpler solution was chosen: functions that take no arguments are functions from the universe polymorphic unit type.

A curried type function is just an instance of \leanm{CurriedFun}.
\begin{leancode}
    abbrev CurriedTypeFun := CurriedFun (Type u) (Type v)
\end{leancode}



Considering all this complexity, it is easy to see why Avigad et al made all the formalizations and
constructions in terms of uncurried functions. 
Still, uncurried functions feel very unidiomatic and users will rightfully expect their (co)datatypes
to function as curried type functions. 
It would be interesting to see whether it is possible to reformulate the formalization of QPFs in
terms of curried functions. 
For the time being, we'll satisfy ourselves with hiding these details throughs
\leanm{TypeFun.curried} and \leanm{TypeFun.ofCurried} conversions.



\section{Make MvQpf automatically assume MvFunctor}
The following change might feel overwhelmingly underwhelming, but it presents a considerably quality 
of life improvement for the \leanm{MvQpf} typeclass. Originally, the latter was defined as
%LEANIGNORE
\begin{leancode}
    class MvQpf {n : Nat} (F : TypeFun n) [MvFunctor F] where
        -- ...
\end{leancode}
This makes sense, \lean{F} can only be a QPF if it is a functor in the first place.
However, when declared like this, the type of \leanm{MvQpf} is 

%LEANIGNORE
\begin{leancode}
    {n : Nat} → (F : TypeFun n) → [MvFunctor F] → Type _
\end{leancode}
In particular, this means we cannot write \lean{MvQpf F}, unless an instance of \lean{MvFunctor F} can be inferred. For concrete QPFs this is generally not problematic, but when \lean{F} is a variable, this restriction becomes annoying. 

For example, if we wish to formalize ``Let \lean{F} be an $n$-ary QPF'', we would like to simply write ``\lean{F} is an $n$-ary type function, and there is an instance of \lean{MvQpf F}''. Like so
\begin{leancode}
    variable (F : TypeFun n) [MvQpf F]
\end{leancode}

With the new definition this works, but under the old definition we would have to explictly require the \lean{MvFunctor F} instance as well. 
Even worse, in some situations different mentions of \lean{MvQpf F} might infer different \lean{MvFunctor F} instances, causing surprising type mismatches. Under the new definition, \lean{MvQpf F} has no further implicit arguments (the value for \lean{n} is fixed by \lean{F}), and such situations can no longer occur.


\section{Type class inference for vectors}

Composition of an $n$-ary functor \lean{F} with $m$-ary functors \lean{G₀, G₁, ..., Gₙ₋₁} originally took the following variables.

%LEANIGNORE
\begin{leancode}
    variable {n m : Nat} 
             (F : TypeVec.{u} n → Type _) 
             [fF : MvFunctor F] 
             [q : MvQpf F] 
             (G : Fin2 n → TypeVec.{u} m → Type u)
             [fG : ∀ i, MvFunctor (G i)] 
             [q' : ∀ i, MvQpf (G i)]
\end{leancode}

Firstly, by the preceding section, we can leave out the \lean{MvFunctor} assumptions, since they are now part of the \lean{MvQpf} assumptions.

Secondly, the last variable, \lean{q'}, states that \lean{G i}, for every \lean{i} of type \lean{Fin2 n}, is a QPF.
The square brackets indicate that it is a \emph{typeclass variable}, which should be filled in by typeclass \emph{inference}.

As there are only $n$ inhabitants of \lean{Fin2 n}, the universally quantified inference problem \lean{∀ i, MvQpf (G i)} neatly reduces to $n$ non-qualified inference problems \lean{MvQpf (G 0)}, \lean{MvQpf (G 1)}, etc.

However, Lean's inference engine does not seem to be able to make this step by itself, failing to infer an instance for
\lean{∀ i, MvQpf (G i)} even if an instance of \lean{MvQpf} can be inferred for each individual type function \lean{Gᵢ}.

So, we introduce a new typeclass, \lean{VecMvQpf}, which wraps the universally quantified typeclass problem.
\begin{leancode}
    class VecMvQpf (G : Vec (TypeFun m) n) where
        prop : ∀ i, MvQpf (G i)
\end{leancode}

Then we can register instances by recursion on the size $n$ of the vector $G$.
For the base case $n=0$, the vector \lean{G} is empty, and its vacuous to say all elements are QPFs.

%LEANIGNORE
\begin{leancode}
    instance instNil    (G : Vec (TypeFun m) 0) : VecMvQpf G
\end{leancode}

For $n+1$, we recurse in the \lean{succ} typeclass variable.

%LEANIGNORE
\begin{leancode}
    instance instSucc   (G : Vec (TypeFun m) (n + 1)) 
                        [zero : MvQpf (G .fz)]
                        [succ : VecMvQpf (fun i => G i.fs)] : 
                            VecMvQpf G 
\end{leancode}

There is no need to write typeclass variables in terms of \lean{VecMvQpf} because of the following instance.
%LEANIGNORE
\begin{leancode}
    instance instUnbox [inst : VecMvQpf G] : 
        ∀i, MvQpf (G i)
\end{leancode}

Note that writing \lean{instNil} and \lean{instSucc} in terms of universally qualified \lean{MvQpf} does not work.
It seems that Leans inference engine puts a limit on recursion depth when trying to infer a universally quantified typeclass problem, whereas it will recurse deeper for \lean{VecMvQpf}.





\section{Universe polymorphic finite type}
\label{sec:enhance:pfin2}
Originally, \lean{Fin2} was defined as the following, straightforward, inductive family, as seen in \cref{sec:ind_families}.
\begin{leancode}
    inductive Fin2 : Nat → Type
    | fz : Fin2 (n+1)
    | fs : Fin2 n → Fin2 (n+1)
\end{leancode}

However, this definition forces \lean{Fin2} to live in \Type.
During the project a need arose for a finite type with exactly $n$ inhabitants, but in arbitrary universes. Thus, the \emph{universe polymorphic} \lean{PFin2} type was added.
\begin{leancode}
    inductive PFin2 : Nat → Type u
    | fz : PFin2 (n+1)
    | fs : PFin2 n → Fin2 (n+1)
\end{leancode}
Whence \lean{Fin2} was changed to just be an alias for \lean{PFin2.{0}}.
Of course, most theorems and definitions for \lean{Fin2} were easily redefined in terms of \lean{PFin2}.





\begin{leanhidden}
    end Enhancing

    namespace Procedure
\end{leanhidden}




\chapter{A procedure for synthesizing functors from a specification}
\label{ch:procedure}

This chapter will establish a procedure that transforms a specifications of a (co)datatype
into the proper constructions on QPFs.
It will do so in the abstract, focusing on the details of the procedure, rather than implementation
details of the Lean meta-programming system (which will be covered in the next chapter).


\section{Shape types}

Arguably the simplest, and most fundamental, inductive types are \leanm{Sum α β} and \leanm{Prod α β},
representing "either α or β" and "a pair of α and β", respectively.
They can be defined as

\begin{center}
\begin{minipage}[t]{0.45\linewidth}
    \begin{leancode}
inductive Sum α β
  | inl : α → Sum α β
  | inr : β → Sum α β
    \end{leancode}
\end{minipage}
\begin{minipage}[t]{0.45\linewidth}
    \begin{leancode}    
inductive Prod α β
  | mk : α → β → Prod α β
    \end{leancode}
\end{minipage}
\end{center}

They are also examples of what we will call \emph{shape} types.
\begin{definition}
    A \emph{shape} type is an inductive type \leanm{Foo α_1, ..., α_n}, 
    where each constructor takes only arguments of types in $\{α_1, ..., α_n\}$.
\end{definition}
That is, each constructor's arguments must be typed as one of the parameters to the shape type.
Let's make this a bit clearer by look at examples that are \textbf{not} shape types. 

%LEAN namespace BadExample
\begin{leancode}
    inductive MyList α
      | nil  : MyList α 
      | cons : α → MyList α → MyList α

    inductive ListWrapper α
      | mk : List α → ListWrapper α

    inductive NatWrapper
      | mk : Nat → NatWrapper
\end{leancode}
%LEAN end BadExample

The only parameter to \leanm{MyList} is α, but the \leanm{cons} constructor takes a \leanm{MyList α} as second argument,
so \leanm{MyList} is not a shape type.
Similarly, \leanm{ListWrapper.mk} (resp. \leanm{NatWrapper.mk}) takes an argument of type \leanm{List α} (resp. \leanm{Nat}),
which are not type parameters, so these types are not shapes either.

Notice that shape types are non-recursive and do not depend on any other types, as a direct consequence 
of the definition. This makes them easy to translate into a polynomial functor. 

\begin{remark}
    One way to do this translation is to realize that all shape functors can be defined as a
    composition of sums and products. 
    This is similar to what the datatype package for Isabelle/HOL does.
    We'll use a different, slightly more monolithic approach.
\end{remark}

Recall that polynomial functors are defined as
\begin{leancode}
    structure MvPFunctor (n : Nat) :=
      (A : Type u) (B : A → TypeVec n)
\end{leancode}


Let us return to the example of sum and product types. 
For the ``head'' type (\leanm{A}), we will take a type that has exactly as many constructor as
the shape type, but such that each constructor is a constant (i.e., takes no arguments).
Note that the head type does not take any type parameters. 

\begin{center}
    \begin{minipage}[t]{0.45\linewidth}
        \begin{leancode}
    inductive Sum.HeadT
      | inl : Sum.HeadT
      | inr : Sum.HeadT
        \end{leancode}
    \end{minipage}
    \begin{minipage}[t]{0.45\linewidth}
        \begin{leancode}    
    inductive Prod.HeadT
      | mk : Prod.HeadT
        \end{leancode}
    \end{minipage}
\end{center}

The ``child'' family of types maps each constructor $c$ to a vector of types \leanm{α_c}.
What is most important is the cardinality of each type \leanm{α_c i}, 
because that is what determines the number of arguments of the $i$-th type parameter are needed
to use constructor $c$. 

The concrete structure of these types is not relevant, so we'll always use \leanm{PFin2 m}, the type
of natural numbers less than $m$, to construct a type with cardinality $m$.

\begin{remark}
    Note that \leanm{PFin2 m} is a type we defined ourselves. We prefer it over \leanm{Fin m}, a similar
    type defined by the lean standard library, because our version is \emph{universe polymorphic}.
    We will come back later to what this means and why it is important.
\end{remark}

So, we start by counting for each constructor, how many times it takes an argument of type \leanm{α_i},
for each parameter \leanm{α_i}.
\begin{center}
\begin{tabular}{l|c|c}
    & α & β \\ \hline
    \lean{Sum.inl}  & 1 & 0 \\
    \lean{Sum.inr}  & 0 & 1 \\
    \lean{Prod.mk}  & 1 & 1 \\    
\end{tabular}    
\end{center}

Using these counts, we define the child family of types, and subsequently, the polynomial functor.

\begin{center}
  \begin{leancode}
    def Sum.ChildT : Sum.HeadT → TypeVec 2
      | .inl => ![PFin2 1, PFin2 0]
      | .inr => ![PFin2 0, PFin2 1]

    def Prod.ChildT : Prod.HeadT → TypeVec 2
      | .mk  => ![PFin2 1, PFin2 1]
  \end{leancode}
\end{center}

\begin{remark}
    If the interpreter knowns which type to expect, say \lean{Sum.HeadT}, and we write an identifier with a leading
    dot, like \lean{.inl}, then it will automatically add the type as namespace, concluding that
    we must mean \lean{Sum.HeadT.inl}.
\end{remark}
From here on, the construction is the same for both types;
We'll show it just for \lean{Sum}.

\begin{leancode}
    def Sum.P  : MvPFunctor 2 := MvPFunctor.mk Sum.HeadT  Sum.ChildT
    
    def QpfSum.Internal : TypeFun 2   := MvPFunctor.Obj Sum.P
    def QpfSum : Type → Type → Type := TypeFun.curried QpfSum.Internal
\end{leancode}

And we're done! However, these qpf-based versions of the types are still not very nice to use.
For example, if we want to construct a pair in \leanm{QpfProd}, we have to go through \leanm{MvPFunctor.mk},
which encodes its arguments in a not user-friendly way. 
Namely, to construct \lean{Sum α β} from an \lean{(a : α)}, i.e., use the \lean{inl} constructor, 
it expects something of type
\begin{center}
    \leanm{(Sum.ChildT .inl) ⟹ ![α, β]}
\end{center}
Which is shorthand for, 
\begin{center}
    (i : PFin 2) → (\leanm{![PFin2 1, PFin 0] i → ![α, β] i})
\end{center}
That is, a function \leanm{PFin2 1 → α} and a function \leanm{PFin2 0 → β}.
\begin{remark}
    Note that vectors are indexed right-to-left, so \lean{![α, β]} is β
    and \lean{![α, β] 1} is α
\end{remark}

Recall that we defined vectors of size $n$ as functions \lean{PFin2 n → α}, so 


\begin{leancode}
    def QpfSum.inl {α β} (a : α) : QpfSum α β :=
      MvPFunctor.mk .inl (fun (i : PFin 2) => match i with
        | 1 => ![a]
        | 0 => ![]
      )
\end{leancode}


We could generate these constructors automatically, but the inner details will still be exposed
when a user tries to destruct an element of \lean{QpfSum α β}.
Clearly, this is not an ideal definition.

\subsection{MvQpf.ofPolynomial}
The solution is to not reinvent the wheel quite as much.
The \leanm{inductive} version of \lean{Sum} and \lean{Prod} (and, indeed any shape type) works
perfectly fine, and is much easier to work with than the polynomial functor-based version.

In fact, the goal of this part of the procedure is not to redefine shape types, it is to show that
they are QPFs by deriving an instance of \lean{MvQpf} (for the uncurried version).
The way to do this is \lean{MvQpf.ofPolynomial}.

%LEANIGNORE
\begin{leancode}
    def ofPolynomial {F : TypeFun n} 
                     (P : MvPFunctor n) 
                     (box    : ∀{α}, F α → P.Obj α) 
                     (unbox  : ∀{α}, P.Obj α → F α) 
                     (box_unbox_id : ∀{α} (x : P.Obj α), box (unbox x) = x)
                     (unbox_box_id : ∀{α} (x : F α), unbox (box x) = x)
                  : MvQpf F
\end{leancode}

If we can provide an isomorphism between \lean{TypeFun.ofCurried Sum} and the polynomial functor \lean{Sum.P}, 
then \lean{ofPolynomial} shows that the former is a QPF.

\begin{todo}
    Maybe explain how box, unbox, etc. are generated?
\end{todo}






\section{Recursive and corecursive types}
Now we know how to turn any shape type into a qpf-based datatype.
If a type is recursive, but otherwise does not mention other types, we can transform it into a shape
type.
Namely, by adding an extra variable and substituting it for all (co)recursive occurences of the type
to be defined.

For example, the shape of \lean{MyList α}, defined at the start of the previous section, is
\begin{leancode}
    inductive List.Shape α ρ
      | nil  : Shape α ρ
      | cons : α → ρ → Shape α ρ
\end{leancode}
This is a valid shape type, so we follow the procedure above to derive an instance of \lean{MvQpf}.
To get rid of the extra variable \lean{ρ}, we simply take the fixpoint.
\begin{leancode}
    def QpfList.Internal : TypeFun 2 
        := MvQpf.Fix (TypeFun.ofCurried MyList.Shape)

\end{leancode}

\begin{todo}
    Explain cofixpoint
\end{todo}



\section{Composition pipeline}
Finally, we are ready to discuss (co)datatypes that are composed of other (co)datatypes.

The running example for this section will be the rose tree; leaves are labelled with \lean{α}, while
internal nodes are labelled with \lean{β} and can have an finite, non-zero number of children.
\begin{leancode}
    data QpfTree α β
      | leaf : α → QpfTree α β
      | node : β → QpfTree α β → QpfList (QpfTree α β) → QpfTree α β
\end{leancode}

The type is recursive, so we introduce the fresh parameter as before.
\begin{leancode}
    data QpfTree.Nonrecursive α β ρ
      | leaf : α → QpfTree α β ρ
      | node : β → ρ → QpfList ρ → QpfTree α β ρ
\end{leancode}

Then, we go through each argument type which is not just a parameter, and substitute
it with a fresh parameter.

\begin{leancode}
    data QpfTree.Shape α β ρ σ₁
      | leaf : α → QpfTree α β ρ σ₁
      | node : β → ρ → σ₁ → QpfTree α β ρ σ₁
\end{leancode}
Remembering that \lean{σ₁} stands for \lean{QpfList ρ}, so we should define the following 
composition, in such a way that \lean{F} is a QPF.
%LEANIGNORE
\begin{leancode}
    def F α β ρ := QpfTree.Shape α β ρ (QpfList ρ)
\end{leancode}


\subsection{Parameter reuse}
Of course, multiple occurences of the same non-parameter type don't nead a fresh variable each.
Suppose we had a constructor that takes two list, like
%LEANIGNORE
\begin{leancode}
    | node₂ : β → ρ → QpfList ρ → QpfList ρ → QpfTree α β ρ
\end{leancode}
Then we can reuse the same fresh parameter \lean{σ₁} for both occurences.
%LEANIGNORE
\begin{leancode}
    | node₂ : β → ρ → σ₁ → σ₁ → QpfTree α β ρ σ₁
\end{leancode}

On the other hand, if a non-parameter type also occurs as a subexpression of another type, then
we will not substitute it with the same parameter.
The example gets a bit contrived, but suppose nodes take both a list of children, and a nested list 
of lists of children.
%LEANIGNORE
\begin{leancode}
    | node₃ : β → ρ → QpfList ρ → QpfList (QpfList ρ) → QpfTree α β ρ
\end{leancode}
Then we can reuse the same fresh parameter \lean{σ₁} for both occurences.
%LEANIGNORE
\begin{leancode}
    | node₃ : β → ρ → σ₁ → σ₂ → QpfTree α β ρ σ₁ σ₂
\end{leancode}
Where \lean{σ₁} stands for \lean{QpfList ρ}, as before, and \lean{σ₂} stands for 
\lean{QpfList (QpfList ρ)}.

\begin{todo}
    Bring attention back to the initial example
\end{todo}


\subsection{Solving for compositions}

The question remains, how do we show that \lean{F} is a QPF.
Recall the desired definition is
%LEANIGNORE
\begin{leancode}
    F α β ρ = QpfTree.Shape α β ρ (QpfList ρ)
\end{leancode}

The \emph{composition pipeline} translates such an equation to a definition of \lean{F} in terms of the appropriate construction on QPF, such that: (a) \lean{F} is known to be a QPF, and (b) \lean{F α β ρ} is indeed equivalent to the desired \lean{QpfTree.Shape α β ρ (QpfList ρ)}.

As the name ``composition pipeline'' alludes, we are defining compositions of QPFs. Formally, \lean{MvQpf.Comp} has signature:
\begin{center}
    \lean{TypeFun n → Vec (TypeFun m) n → TypeFun m}
\end{center}
An $n$-ary type function \lean{F} is composed with an $n$-sized vector of $m$-ary type functions, resulting in an $m$-ary type function. The composition is essentially defined as
%LEANIGNORE
\begin{leancode}
    (Comp F ![G₁, ..., Gₙ]) ![α₁, ..., αₘ] 
                = F ![G₁ ![α₁, ..., αₘ], ..., Gₘ ![α₁, ..., αₘ]]
\end{leancode}
All arguments \lean{αᵢ} are broadcast to all functors \lean{Gⱼ}, meaning we don't have to worry about argument duplication or reordering.

Continuing with the example, we are going to define \lean{F} as \lean{Comp QpfTree.Shape ![G₁, G₂, G₃, G₄]}, for some functors \lean{G₁}, \lean{G₂}, \lean{G₃} and \lean{G₄}, satisfying the following equations:
\begin{leancode}
    G₁ α β ρ = α                G₃ α β ρ = ρ
    G₂ α β ρ = β                G₄ α β ρ = (QpfList ρ)
\end{leancode}
The first three equations are trivial, they describe projection functors. 
The last equation betrays the recursive nature of the composition pipeline.

\begin{todo}
    Mention dead variables here, or somewhere before.
\end{todo}

In fact, we can identify three kinds of functors:
\begin{itemize}
    \item \emph{Projections: } The right-hand-side of the equation is just a parameter, as in \lean{G₁ α β ρ = α}
    \item \emph{Constants: } The rhs does not mention the (live) parameters at all, e.g., \lean{G α β = Nat} or \lean{G (x y : Type) α β = x → y}.
    \item \emph{Compositions: } The rhs is an application of a QPF
\end{itemize}

\begin{remark}
    Other kind of expressions, such as dependent arrows \lean{(a : α) → ...} or anonymous functions \leanm{fun γ => ...}, are not supported. Non-dependent arrows \lean{α → β} are interpreted as the application of \lean{(α → ⋅)} to \lean{β}.
\end{remark}

Projections are trivial to identify, and for constants we only have to verify that the target expression contains none of the live parameters. 

In all other cases, we try to find the largest expression \lean{G}, such that \lean{G} is a $k$-ary QPF, for some $k$, and we can write the target equation as
\lean{F ... = G e₁ ... eₖ}.
If no such \lean{G} exists, it means the original equation was not valid.


Then, we recursively call the composition pipeline, each time defining a new functor \lean{Hᵢ ... = eᵢ}, where \lean{Hᵢ} takes the same parameter as the original desired functor \lean{F}.

Finally, \lean{F} can simply be defined as the composition of \lean{G} with \lean{![H₁, ..., Hₘ]}.




\section{Universe considerations}
\begin{todo}
    Explain universe polymorphism (i.e., why PFin2).

    Explain why HeadT is not universe polymorphic yet (bug in our version of lean)
\end{todo}


\section{A final example}
\begin{todo}
    Do the entire procedure for
    codata NatStream
    | mk : Nat → NatStream → NatStream
\end{todo}




\newpage 
\newpage








% We will start by giving example specifications, and showing how to represent each as a (co)fixpoint
% of a QPF manually.

% The \leanm{inductive} keyword encompasses three concepts: sums, products, and recursion.
% Let's forget about the latter for a second, and look at a non-recursive type
% \begin{leancode}
%     inductive Foo (α β γ : Type)
%     | bar : α → β → Foo α β γ
%     | qux : γ → Foo α β γ
% \end{leancode}
% We can replace the two arguments of the \leanm{bar} constructor by their product.
% \begin{leancode}
%     inductive Foo₂ (α β γ : Type)
%     | bar : (α × β) → Foo₂ α β γ
%     | qux : γ → Foo₂ α β γ
% \end{leancode}
% Having two constructor with a single argument just means taking their sum.
% \begin{leancode}
%     def Foo₃ (α β γ : Type) :=
%         (α × β) ⊕ β
% \end{leancode}




% \section{Polynomial Functors}

% Recall that we formalized polynomial functors, and their action on types, as  
% \begin{leancode}
%     structure MvPFunctor (n : Nat) :=
%         (A : Type u) (B : A → TypeVec.{u} n)

%     def MvPFunctor.Obj (P : MvPFunctor n) : TypeFun n
%         := fun α => Σ a : P.A, P.B a ⟹ α
% \end{leancode}

% That is, a polynomial functor $P$ is defined by some type $A$, where each element represents some 
% constructor of type $P(x_0, ..., x_{n-1})$, and a family of types $B_{a, i}$, with $a ∈ A$ and $i < n$, 
% where each element of $B_{a,i}$ is a label for an argument of type $x_i$ needed by constructor $a$.

% These can of course be any type, and this flexibility is useful in certain constructions,
% but ultimately the functor is defined by their \emph{cardinality}, i.e., how many inhabitants types 
% $A$ and $B_{a,i}$ have. Any additional structure of these types is not relevant for the behaviour of 
% the functor.

% Consequently, we can express any polynomial functor (up to isomorphism, at least) with the following
% shorthand.

% \begin{leancode}
%     def MvPFunctor.mk' {n : Nat} (ctors : List (Vec Nat n)) 
%         : MvPFunctor n
%     :=  let A := PFin2 ctors.length
%         let B := fun a i => PFin2 (ctors.get a.toFin i)
%         ⟨A, B⟩
% \end{leancode}

% Here \leanm{PFin2 n} is the type of natural numbers strictly less than $n$, which gives us an easy
% way to construct types of arbitrary (but finite) cardinality $n$.

% In effect, \leanm{ctors} is a matrix of fixed width $n$ (but arbitrary height). 
% Each row represents a constructor, the value in the $i$-th column tells us how many elements of the 
% $i$-th type argument are required in the constructor.

% \subsubsection*{Products \& Sums}
% For example, consider a (binary) product, which could be inductively defined as 
% \begin{leancode}
%     inductive Prod α β
%       | mk : α → U → Prod T U
% \end{leancode}

% We can define the corresponding functor, using our abbreviation as
% \begin{leancode}
%     def Prod.P : MvPFunctor 2 
%       := .mk' [
%         ![1, 1]
%       ]
% \end{leancode}
% At a glance, we see that \leanm{P ![α, β]} has a single constructor, and this constructor takes one
% argument of type \leanm{α} and one argument of \leanm{β}.
% This definition corresponds to the following
% \begin{leancode}
%     def Prod.P' : MvPFunctor 2 
%       :=  let A := PFin2 1
%           let B := fun _ => ![PFin2 1, PFin2 1]
%           ⟨A, B⟩
% \end{leancode}



% Another fundamental functor is the (binary) sum. Inductively, it looks like this
% \begin{leancode}
%     inductive Sum α β 
%       | inl : α → Sum α β 
%       | inl : β → Sum α β 
% \end{leancode}
% It has two constructors, so we use a matrix with two rows to define the polynomial functor.
% \begin{leancode}
%     def Sum.P : MvPFunctor
% \end{leancode}




% \subsection*{Universe polymorphism}

% As an aside, Lean does provide a standard \leanm{Fin n} type which encodes naturals less than $n$.
% However, \leanm{Fin n} has type \leanm{Type}, which forces the arguments to any functor \leanm{P} with
% \leanm{P.A = Fin n} to be in \leanm{Type 0} as well.

% To illustrate, here is a definition of the product functor, but now in terms of \leanm{Fin}
% \begin{leancode}
%     def Prod.Q : MvPFunctor 2 
%       :=  let A := Fin 1
%           let B := fun _ => ![Fin 1, Fin 1]
%           ⟨A, B⟩

%     -- `Nat` lives in `Type', so both functors are fine
%     #check  
% \end{leancode}
% First, consider the pair \leanm{(Nat, Nat)}. \leanm{Nat} lives in \leanm{Type}, so both functors are 
% fine
% \begin{leancode}
%     #check (P.Obj ![Nat, Nat] : Type)       -- ✓
%     #check (Q.Obj ![Nat, Nat] : Type)       -- ✓
% \end{leancode}
% Then, suppose some \leanm{X} that lives in a higher universe.
% \leanm{P} is able to adjust. 
% \begin{leancode}
%     variable (X : Type 1)
%     #check (P.Obj ![X, X] : Type 1)         -- ✓
% \end{leancode}
% However, \leanm{Q} complains that it expects \leanm{X} to live in \leanm{Type}.
% \begin{leancode}    
%     #check Q.Obj ![X, X]                    -- ×            
%     -- application type mismatch
%     --   Vec.append1 Vec.nil X
%     -- argument
%     --   X
%     -- has type
%     --   Type 1 : Type 2
%     -- but is expected to have type
%     --   Type : Type 1
% \end{leancode}

% Note that \leanm{P} still requires all arguments to live in the same universe, so
% \begin{leancode}
%     #check P.Obj ![X, Nat]                  -- ×
% \end{leancode}
% %     -- application type mismatch
% %     --   Vec.append1 (Vec.append1 Vec.nil ℕ) X
% %     -- argument
% %     --   X
% %     -- has type
% %     --   Type 1 : Type 2
% %     -- but is expected to have type
% %     --   Type : Type 1
% % \end{leancode}
% does not typecheck.



% \subsection*{Sum}
% For example, the type \leanm{Sum T U}, representing the disjoint union of types \leanm{T} and \leanm{U},
% is a polynomial functor. It could be specified as:
% \begin{leancode}
%     data Sum T U
%     | inl : T → Sum T U
%     | inr : U → Sum T U
% \end{leancode}
% For $A$, we take a simple enumeration of the constructors
% \begin{leancode}
%     inductive Sum.A
%     | inl : Sum.A
%     | inr : Sum.A
% \end{leancode}
% For $B$, we use the following
% \begin{leancode}
%     def Sum.B : Sum.A → TypeVec n
%     | .inl => ![Unit, Empty]
%     | .inr => ![Empty, Unit]
% \end{leancode}
% This means that an element of \leanm{Sum T U} made with constructor \leanm{inl} contains one inhabitant of \leanm{T} (\leanm{Unit} has exactly one inhabitant) and no inhabitants of \leanm{U} (as the name implies, \leanm{Empty} is not inhabited). Conversely, elements made with constructor \leanm{inr} contain one inhabitant of \leanm{U} and no inhabitant of \leanm{T}.



























\chapter{Implementing the procedure as a proof of concept}
\label{ch:implementing}


In the preceding chapter we explored exactly how to translate a definitional specification of a (co)datatype to the fundamental constructions that can encode that (co)datatype.
In the current chapter, we will discuss the technical details of: (a) how to extend lean so that \data and \codata can be used in the same way as \inductive, and (b) how to extend the user's environment with definitions in terms of these constructions.

That is, we are going to dig deeper into the technical details of the metaprogramming system.
We still don't assume knowledge of Lean, specifically, but we do require some more familiarity with functional programming (roughly, what is a Monad, and how do we use it for side effects). \cite{ullrichNotationsHygienicMacro2022}\cite{paulinoMetaprogrammingLean}


\section{Extending Lean's syntax}
\label{sec:syntax}

Like many modern theorem provers, Lean (4) has facilities that allow us to register custom syntax for specific functions. For example, the following macro allows us to write \lean{Γ ⊢ 0 : Nat} in the familiar syntax for type checking, translating it to the application \lean{Typing Γ 0 Nat}.
\begin{leancode}
    macro Γ:term " ⊢ " e:term " : " t:term : term => `(Typing $Γ $e $t)
\end{leancode}
Actually, this \keyword{macro} declaration is translated into two parts.

\begin{leancode}
    syntax term " ⊢ " term " : " term : term
    macro_rules
      | `($Γ ⊢ $e : $t) => `(Typing $Γ $e $t)
\end{leancode}

Firstly, the \keyword{syntax} declaration defines a \emph{parser extension}.
Lean's grammar does not have a dedicated macro invocation syntax, instead, such parser extensions tell the parser how to transform source code into an \emph{abstract syntax tree}. That is, an object of type \lean{Syntax}.

\begin{remark}
    In more recent versions of Lean, the \lean{Syntax} type has been replaced by \lean{TSyntax cat}, where \lean{cat} is the (statically known) syntax category (e.g., \lean{term} or \lean{command}).
    Our code was written before this overhaul, thus we generally refer to the old way in this chapter.
\end{remark}


Here, specifically, we're stating that three terms, mixed with \lean{⊢} and \lean{:} form a new term. For example, \lean{Γ ⊢ 1 + 2 * 3 : Nat} will be parsed into
\begin{todo}
    Syntax tree for \lean{Γ ⊢ 1 + 2 * 3 : Nat}
\end{todo}
Notice how the tree makes grouping and precedence explicit.

Then, the \keyword{macro\_rules}
part defines the \emph{semantics} of the macro, as a substitution. We both match on, and create new syntax trees, using \emph{syntax quotations} (written as \lean{`()}). We can use a variable of type \lean{Syntax} in a syntax quotation as, e.g, \lean{`(\$Γ)}, this is called an \emph{anti-quotation}.

Clearly, though, \data{} and \codata{} are not just simple substitutions.
We could, in theory, replace the right hand side of a \keyword{macro\_rules} match arm 
with arbitrary code that produces a \lean{Syntax} object, and in this way, define a \emph{procedural macro}.
This is, however, not idiomatic, procedural macros are usually defined as an \emph{elaborator}.


\subsection{Data and Codata Syntax}
Before we get to what an elaborator is, we'll take a few steps back and consider how, exactly, we should define the parser extensions for \data{} and \codata{}.

The flexibility and extensibility of Lean is not just for users. The Lean 4 compiler/interpreter is mostly written in Lean 4 itself, and it turns out that a lot of ``native'' syntax is implemented as a macro. Amongst them, \inductive{}.

The following defines a \lean{Parser} object for the \inductive{} syntax.
\begin{leancode}
    def «inductive» := leading_parser "inductive " >> declId >> optDeclSig 
                        >> optional (symbol " :=" <|> " where") 
                        >> many ctor 
                        >> optDeriving
\end{leancode}

Where \lean{declId}, \lean{optDeclSig}, etc. are all parsers, or parser combinators. Combinators \lean{a >> b} and \lean{a <|> b} mean ``first parse \lean{a}, then \lean{b}'' and ``parse \lean{a} \emph{or} \lean{b}'', respectively.

\begin{todo}
    Should I explain the \lean{«...»} brackets here?
\end{todo}

It is lower-level than the \keyword{syntax} declaration we saw before, but very similar: this parser accepts an ``inductive'' \emph{atom} (or, literal), followed by a declaration id (\lean{declId}), an optional signature (\lean{optDeclSig}), optionally a `` :='' or ``where'' atom, followed by zero or more (\lean{many}) constructor specifications (\lean{ctor}), and finally, an optional list of typeclasses to derive (\lean{optDeriving}).

This \lean{Parser} instance is then used in the \lean{declaration} parser.
\begin{leancode}
    @[builtinCommandParser] def declaration := leading_parser
            declModifiers false >> (/- ... <|> -/ «instance» /- <|> ... -/)
\end{leancode}

The \lean{builtinCommandParser} attribute registers \lean{declaration} as a builtin (i.e., native) syntax extension for the \lean{command} category.

\begin{remark}
    There are many syntax categories, of which \lean{term} and \lean{command} are by far the most common.
    The former, \lean{term}, is the syntax category for terms, e.g., \lean{x + y} or {Type → Nat → Type}, whereas \lean{command} is the category for top-level commands, such as \inductive{}, but also definitions (\keyword{def}), theorems (\keyword{theorem}), etc.
\end{remark}


We declared that we want \data{} to be (mostly) usable as a drop-in replacement for \inductive{}, so we copy the latter's parser verbatim, replacing the ``inductive'' atom with ``data'', respectively ``codata''.
\begin{leancode}
    def data := leading_parser "data " >> declId  >> optDeclSig  
                        >> Parser.optional  (symbol " :=" <|> " where") 
                        >> many ctor 
                        >> optDeriving

    def codata := /- ... -/
\end{leancode}

Unlike before, we are not defining builtin syntax, so we use the \lean{commandParser} attribute to define the parser extension.

\begin{leancode}
    @[commandParser] def declaration := leading_parser 
        declModifiers false >> (data <|> codata)
\end{leancode}

And now, Lean knows how to successfully parse:
\begin{badleancode}
    data Foo α
      | foo : α → Foo α
\end{badleancode}

However, we only defined the syntax, not the semantics. 
The code above still fails, complaining that we did not define an \emph{elaboration function} for \lean{declaration}.


\subsection{Unsupported syntax}
Note that parser extensions are not strictly about which syntax is \emph{supported}, rather, they declare which syntax this macro is \emph{responsible} for.
Suppose, for example, that a user tried to derive a typeclass for their datatype.
\begin{badleancode}
    data Foo α
      | foo : α → Foo α
      deriving BEq
\end{badleancode}

Although this syntax is accepted by the \data{} parser, we don't actually support deriving typeclasses yet.

Removing the \lean{>> optDeriving} part from the parser definition would bring the accepted syntax closer to what is actually supported, making \lean{Foo} as written above lead to a generic parse error.

However, the user is clearly trying to invoke our \data{} macro, and \inductive{} does support such a \keyword{deriving} statement, so it is to be expected that users will try to use it. The generic parse errors are quite obscure, and bad at communicating to the user that \keyword{deriving} statements are not supported; a user might reasonably think the parse error is because of some (non-existent) typo.

So instead, we have the parser accept exactly the same syntax as \inductive{}, and in the \emph{elaborator} we include extra verification logic to raise a custom, informative error when a user tries to use unsupported syntax.
In this way, \data{} is truly a drop-in replacement for \inductive{}, syntax-wise, and any errors will guide the user and explain unsupported syntax.



\section{Defining the Semantics of a Macro}
With the parser extension in place, the next step is to define an \emph{elaborator}.
We already mentioned that the two main syntax categories are terms and commands, each has their own kind of elaborator.

Terms are translated to expressions in the core logic of Lean (as encoded by the \lean{Expr} type). A \emph{term elaborator} is thus a function \lean{Syntax → TermElabM Expr}, where \lean{TermElabM} is the term elaboration monad. This monad gives (read-only) access to the \emph{environment} (i.e., declarations and imports that the term can refer to) and \emph{metavariable context} (roughly speaking, a metavariable represents a hole in the program that should be synthesized/inferred at some point during compilation).


Commands, on the other hand, are not translated, but used for their side effect. Hence, the type of a \emph{command elaborator} is \lean{Syntax → CommandElabM Unit}, where the \lean{CommandElabM} monad allows for four kinds of side effects: 
\begin{enumerate}
    \item Modifying the environment (e.g., \inductive{}, \keyword{def}, \keyword{theorem}),
    \item Logging messages to inform the user (e.g., \lean{\#check}, \lean{\#print}, \lean{\#eval}),
    \item Performing IO, and
    \item Throwing errors
\end{enumerate}

Although \lean{TermElabM} neither extends, nor is extended by \lean{CommandElabM}, it is common to elaborate terms in a command elaborator, e.g., by using \lean{liftTermElabM} or \lean{runTermElabM}.







\subsection{Command Elaborator for Inductive Declarations}
Once again, we draw inspiration from \inductive{}, whose elaborator can be found in the Lean compiler source at \texttt{Lean/Elab/Declaration.lean} and \texttt{Lean/Elab/Inductive.lean}.

Elaboration starts in the generic declaration elaborator, which checks what the kind of declaration it is given, and defers to \lean{elabInductive} (in case of an inductive declaration). The latter, in turn, calls \lean{inductiveSyntaxToView} to transform the \lean{Syntax} object into a \lean{InductiveView} and defers to \lean{elabInductiveViews}.

This \lean{InductiveView} is a thin wrapper around the syntax tree, allowing us to refer to the different parts of an inductive declaration by name, rather than offset, but crucially, still stores, e.g., constructor types as \lean{Syntax} objects.

At this point, things like auto bound implicit variables are added, the constructor types are elaborated, and type universes are inferred (if needed), to produce a \lean{InductiveType} object. 
Finally, the \lean{InductiveType} is wrapped in a \lean{Declaration}, added to the environment, and auxiliary constructions are generated with \lean{mkAuxConstructions}.


Most of this work, obviously beside the steps that add inductive declarations to the environment, is also relevant for \data{} and \codata{} declarations.

An attempt was made to copy the code of \lean{elabInductiveViews} (and all private or protected functions it called) and factor out all work that is relevant for both \inductive{} and \data{}/\codata{} declarations into a common function.
However, it turned out that some of the elaboration steps to produce the \lean{InductiveType} object were not desirable for then running the procedure of \cref{ch:procedure} on.

For example, type parameters are added to constructor types as implicit arguments.
\begin{leancode}
    inductive Foo α β
      | mk : α → β → Foo α β

    inductive Bar α
      | mk : {β : Type} → α → β → Bar α

    -- Foo.mk has type `{α: Type} → {β: Type} → α → β → Foo α β`
    -- Bar.mk has type `{α: Type} → {β: Type} → α → β → Bar α`
\end{leancode}
Whereas we would like to give as input to the procedure just (expressions corresponding to) types \lean{α → β → Foo α β} and \lean{{β : Type} → α → β → Bar α}.
It is, of course, possible to detect which of the implicit argument are type parameters, by looking at which variables are passed to \lean{Foo}, resp. \lean{Bar}, but this adds complexity.

In the end, making the required changes was deemed to be too much engineering effort, and a simpler syntactic approach was chosen instead.



\subsection{Adding declarations to the environment}
Suppose we are writing a command elaborator, and as part of it we wish to generate an inductive declaration and add it to the environment. This can be done in multiple ways, in roughly increasing order of both robustness and effort required:
\begin{enumerate}
    \item Generate the relevant source code as a \lean{String}
    \item Generate the relevant syntax tree as a \lean{Syntax} object
    \item Generate a fully elaborated \lean{Declaration} object
\end{enumerate}

The first approach, while easy, is too brittle; \lean{runFrontend} can be used to parse and elaborate the code in a string, but that function is designed to be called with the content of a \texttt{.lean} file of user-written source code, not with code generated during command elaboration.

The last approach requires full elaboration of all terms involved, which, as discussed in the previous section, was deemed too complicated for our prototype.

As such, the second approach was chosen, relying on \emph{syntax quotations} to simplify the generation of syntax trees. 
For example, if we want to define \lean{Foo} as the string \lean{"Bar"}, then
\begin{leancode}
    let stx : Syntax ← `(def Foo := "Bar")
    elabCommand stx
\end{leancode}
Stores in the variable \lean{stx} the parsed syntax tree, and elaborates it in the usual way; \lean{elabCommand} is a builtin function \lean{Syntax → CommandElabM Unit} that takes a \lean{command} syntax tree and calls the appropriate elaborator.

By default, a syntax quotation will try to parse whatever code we write as either a command or a term. There are situations, however, where we want to build up a command (or term)incrementally, requiring us to generate syntax that, by itself, is not a complete command (or term). Imagine, for example, that, given some array \lean{[`A, `B, `C]} of names, we want to generate the inductive type:
\begin{leancode}
    inductive Baz
      | A : Baz
      | B : Baz
      | C : Baz
\end{leancode}
The code to do so might look like the following
\begin{leancode}
    open Lean.Parser.Command in
    def inductiveFromNames (names : Array Name) : CommandElabM Unit := do
      let ident := mkIdent `Baz
      let ctors ← names.mapM fun name =>
      let ctorIdent := mkIdent name
        `(ctor| 
          | $ctorIdent:ident : $ident:ident
        )

      elabCommand (←`(
        inductive $ident:ident
          $[$ctors:ctor]*
      ))
\end{leancode}
Of special interest is the \lean{`(ctor| ...)} syntax quotation, which specifies that the syntax should be parsed with the \lean{ctor} parser.

Do note that the parser cannot examine the values of the \lean{ctorIdent} and \lean{ident} anti-quotations, it treats them as opaque blobs of syntax. Since the parser does not know the syntax category, we help it a bit by specifying it explicitly, as \lean{:ident}.
Similarly, in the final \inductive{} syntax quotation, we specify that \lean{ctors} is an array of syntax of the \lean{ctor} category.

The \lean{\$[...]*} part is called a \emph{splice}, and it allows us to use an array of syntax objects whenever a parser expects a whitespace separated list of things (as is the case with the \lean{many} parser combinator used in the \inductive{} parser).



\section{Implementing the Procedure}
\label{sec:implementing}

Now that we have a general idea of the meta-programming system of lean, and a high-level implementation strategy, let us revisit the procedure from \ref{ch:procedure} and see how its different steps are implemented.

The relevant function signatures are
\begin{leancode}
-- In `Qpf.Macro.Data`

  /-- Defines the "head" type of a polynomial functor-/
  def mkHeadT (view : InductiveView) : CommandElabM Name

  /-- Defines the "child" family of type vectors for an `n`-ary polynomial functor -/
  def mkChildT (view : InductiveView) (r : Replace) (headTName : Name)
               : CommandElabM Name

  /-- Show that the `Shape` type is a qpf, through an isomorphism with the 
      `Shape.P` pfunctor -/
  def mkQpf (shapeView : InductiveView) (ctorArgs : Array CtorArgs) 
            (headT childT P : Syntax) (arity : Nat) 
            : CommandElabM Unit    


  structure MkShapeResult := (r : Replace) (shape : Name) (P : Name)
  /-- Define the "shape" polynomial functor -/
  def mkShape (view: InductiveView) : CommandElabM MkShapeResult


  /-- The "base" type is the shape type with all variables set to the appropriate
      expressions, besides the variable used for (co)-recursive occurences.
      It is the final step before taking the (co)fixpoint -/
  def mkBase (view : InductiveView) : CommandElabM Syntax


  /-- Top-level elaboration for both `data` and `codata` declarations -/
  @[commandElab «declaration»] def elabData : CommandElab

-- In `Qpf.Macro.Comp`
\end{leancode}


\begin{todo}
    Finish this section
\end{todo}


\chapter{Future considerations / current limitations}
\label{ch:limitations}
















\begin{todo}
    


    \begin{itemize}
        \item Universe polymorphic HeadT
        
        \item Quotients don't work yet
              \begin{itemize}
                \item datatypes involving quotients should be marked \lean{noncomputable}, but this modifier is currently propagated to an autogenerated \inductive{} type, but Lean does not accept \leanm{noncomputable inductive}.

                \item We should check which modifiers have to be propagated, and to which of the auto-generated types.
              \end{itemize}
        

        \item Mutually recursive types?
        
        \item User friendly (co)recursion / (co)induction
                \begin{itemize}
                    \item `eliminator`
                    \item integrate with equation compiler
                \end{itemize}
    \end{itemize}
\end{todo}









\chapter{Conclusion}
\label{ch:conclusion}















\begin{leanhidden}
    end Thesis
\end{leanhidden}



\bibliographystyle{ieeetr}
\bibliography{MScThesis}

\end{document}



%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "test"
%%% End: 
