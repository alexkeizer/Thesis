


Welcome everybody, thanks for coming.
I know that for some of my friends and family in the audience, my title, "Implementing a definitional (co)datatype package in Lean 4, based on QPFs", sounds like I'm making up words as I go along.
I really appreciate you coming here, and I hope that by the end of today it will be a bit clearer just what I haev been spending so much of my time on.


========


To begin with, I've been writing this package, this piece of software.
The langauge I've been using is Lean, specifically, version 4 of the Lean system.
Lean is usually introduced as an interactive theorem prover, or proof assistant, meaning, it's a tool to formalize mathematical proofs, and have the machine check them for us.
But, Lean is also a programming language. It's a functional language, so if you know a language like Haskell, Lean might look familiar, and it is a dependently typed language, so it has a very strong and expressive typesystem.


========


In Lean, new datatypes are generally defined as inductive types. Here I'm showing the definition of a list, or a sequence of things.
First, there is the inductive keyword, then the name of the type we're defining;
alpha is a type parameter, so we're being generic over the content of our list.
Then, the following two lines define our constructors.
nil is a constant, and cons is a function taking two arguments, an element of the generic type alpha and a list, to return a new list.

Really, inductive definitions in Lean are quite similar to how we would do inductive definitions on paper.

The way to read this definition is to say:

first, let alpha be an arbitrary type, then nil is a list, also called the empty list, it has no data elements.

And, if head is an alpha and tail is a list of alhas, then cons of head and tail is another list of alphas, namely the one were we put head in front of the existing list tail.

So, starting from the empty list, we just keep adding new elements to the front to construct bigger lists.

Finally, these two constructors are the only ways to construct a list, nothing else is a list.


=======


Based on this specificaion, Lean generates a bunch of usefull things for us.
In particular, it gives us an induction principle, which state that if we can prove that some property P holds for the empty list, and that P of tail implies P of cons head tail, for all combinations of head and tail, then P must hold for all lists.

The induction principle is about of proofs; Lean also give us a recursion principle along the same lines, for computations.

However, all of this only works for finite lists. And indeed, inductive types represent finite structures.



======


Which brings us to the main focus of my thesis: how can we (easily) represent infinite types?
The package I implemented provides a codata command, to define *co*inductive types.
(Coinductive types are also called codatatypes, hence, codata)

CoList is the defined with the same constructors, the kind of shape as List, but now as a coinductive type.
CoList represents potentially infinite lists.


======

The codata command is compositional, we can use CoList to can define the type of infinite trees, where a node consist of an element of alpha, representing some kind of data, and a colist of subtrees.

Trees are interesting, because they can be infinite in two distinct ways:
A tree can be infinitely wide, meaning a node might have infinitely many children, or
a tree can be infinitely deep, meaning there is some infinite path from the root that keeps going deeper, visiting infinitely many nodes.

This definition of CoTree encompasses both: a node can indeed have infinitely many children, because subtrees are stored in a potentially infinite colist, while infinite depth comes from the fact the CoTree is a coinductive type.


======


Now suppose we want trees that are infinitely wide, but only finitely deep.
We can achieve this by defining an *inductive* type, that still uses the coinductive colist to store subtrees.
In this way, the tree is defined with a nested mix of induction and coinduction.
The normal inductive command, however, doesn't compose well with types generated by the codata command,
so the package also contains a data command, for inductive datatypes.
Effectively, data has the same meaning as inductive, but it uses a different mechanism and composes better with codatatypes defined by the codata command.


======

Conversely, we can define finitely wide but infinitely deep trees by sticking with codata as the command, but using a normal inductive List to store subtrees.
Again, mixing induction and coinduction, but in a different way.



=====

The goal of my thesis, thus, is to support coinductive types in Lean.
I am not the first person to think about this; previous work has studied how coinductive types can be modelled in Lean, and provided formalization of a set of basic building blocks for coinductive types, albeit in an older version of Lean.

So, my work has been to port these building blocks to Lean 4, adding a bit to them as I went along. 
But most of all, I have designed a procedure that compiles the high level specifications, such as the ones in the last few slides, and compiles them into applications of the basic building blocks.
Furthermore, I made a proof of concept implementation of the data and codata commands.



======  (7 mins)


The basic building blocks are centered around a notion of *polynomial functors*.
This notion is based on category theory, but for now we can think of it as a type that is defined according to this strict scheme.

That is, we have some type A and a family of types B.
Then, P applied to any type X is the type of pairs (a,f), where the first element, a, is called a shape, and the second element, the contents, is a function from B of a to the argument type X.

Such a function is equivalent to a collection of elements of X, where Ba determines how the number elements in this collection.
If Ba is empty, then the function doesn't store any data,
if Ba is a type with one inhabitant then the functions is equivalent to a single element of X,
if Ba has two inhabitants, the function is equivalent to a pair of X, and so forth



=====

Lets look at an example. The option type is either a constant `none`, denoting the absence of any data, or a single alpha.

We can think of of the two constructors as being the shapes, so we define A to be a type with 2 inhabitants.
For convenience, we name these inhabitants none and some, after the constructors they represent.
Then, as none stores no data, we define B of none to be an empty type, then the corresponding function is trivial, it stores no data.

Some stores one element of alpha, so B of some is a type with exactly one inhabitant.



=====

Another example, a pair of alphas is just two alphas. There is only one constructor, so A is a type with only one inhabitant.
Since there are two alphas stored in a pair, B of mk is a type with exactly two inhabitants.

Here, `Fin n` is just an easy way to define a type with exactly n inhabitants, for arbitrary n.
Notice that we don't really care about the structure of the B types that much, the most important part is how many inhabitants it has.


=====

For a third example, consider the Sum of two types, alpha and beta.
The elements of this sum are either a single alpha, or a single beta.

Now, this type has 2 type parameters, so it doesn't fit in the definition of polynomial functions as I presented them.


====

However, we can generalize the definition.
A polynomial with two arguments is defined not by one family of types, but two families of types.
Then, the elements of P applied to X0 and X1 are triples, still one shape, but two functions, where f0 stores the contents of type X0 and f1 stores the contents of type X1.

Like this, we can generalize polynomial functors to any number of arguments.
But for now, two is enough.



=====

Ok, lets go back to sums.

First off, there are two constructors, so we define A to be a type with two inhabitants.

Then, Really, what we're doing is for each constructor, and each type parameter, counting how many arguments of that type are used by this constructor.
So, if we do all those counts, we get this table, and from there it's straightforward to define the various B types.

For each type, we look at the table and make sure B has that many inhabitants.
We could use Empty or Unit types here, it's just convenient to use Fin everywhere.




=====

This procedure only works for a certain kind of simple types. In particular, it doesn't handle recursive types.
If we look at lists, then notice how the second argument to cons is a list, so list is defined in terms of itself, it's recursive.

List is polynomial, so we can define it in terms of an A and B. It's just that the simple procedure where elements of A are constructors and for B we just count occurences, doesn't work.

What we can do, is transform the specification to just its shape.
That is, we add a new type parameter rho, and substitute it for all recursive occurences of List.
Then we get a simple enough type, for which the counting procedure does work.
So we can show that ListShape is a polynomial functor.

From there, List should be the solution to this equation, where we find some assignment to rho so that ListShape applied to alpha and list of alpha is equivalent to just List of alpha.
A solution to this equation is also called a fixpoint.

In fact, there are two canonical solutions; there is a least solution, which we will call just fixpoint, and there is a greates solution, the cofixpoint.
The difference between these solutions, is that the fixpoint corresponds to a finite repetition, so the fixpoint models inductive types, while the cofixpoint allows for infinite repetitions, the cofixpoint models coinductive types.

You'll notice I used CoList for the second equation. Remember that CoList has the same shape as List, but it has a coinductive interpretation.
So, it's the cofixpoint.

This is the only difference between the data and codata commands: data takes a fixpoint, codata a cofixpoint.

It's easy enough to say that we want a solution to these equations, but what's to say such a solution even exists.
Well, if we know that ListShape is a polynomial functor, then one off the basic building blocks provided to us is the construction of the fix or cofixpoint.
You might also know them as the W- or M-type of a polynomial functor.

So, these solutions exist, and we know how te construct them.



===== (7/7,5) + (~7,5 mins)


Let's continue with the infinite trees example. This type, too, is recursive, or I should *co*recursive because it's a coinductive type.
All the same, we introduce a new type parameter rho and substitute it.

This time, however, the result is not quite simple enough yet.
There is still the CoList type that we don't really know how to deal with in our counting method.

Well, adding new type parameters worked for us before, so let's do it again.
We add sigma and remember that sigma stands for CoList rho.
Now we do have a simple enough type, and we can show that shape is polynomial.

We want to define a polynomial functor P according to this equation, were we substitute back the desired meaning of sigma


=====

The basic building block to do this with, is composition.
In this case, Shape takes three arguments, and the desired functor takes two, so we compose Shape with three binary polynomial functors.
The result, when applied to alpha and rho, is an application of Shape where the first argument is obtained from the first functor, the second argument from the second functor and the third argument ffrom the third functor.

We can compare this composition with the original equation, and then we obtain another three equations that define the three G functors.
This part of the procedure, called the composition pipeline, is recursive. It takes as input a desired equality, and we try to keep breaking this equation down.

The first two of these new functors are just projections to one of their arguments. Those are easy to define as polynomial functors.
The third equation is again an application of a existing polynomial functor, so that is defined through composition again.

This composition generates yet another equation. This one is again just a projection.
For technical reasons, we index the arguments from right to left.



=====

The composition pipeline generates a bunch of intermediate equations, but we don't have to define those all seperately.
We can throw it all together into one big definition of P.

Then, remember that we're defining codatatype, and codatatype means cofixpoint. So we finally define CoTree as the CoFixpoint of that big composition.
And this is how the compilation procedure works.



===== 17,5

Well, mostly. 
Polynomial functors can represent a lot of types, but not all.

In particular, Lean supports so called quotient types. A common example is the Multiset.
A multiset is a bit like a list, except we don't care about the order of elements.

For example, the list 1,2,2 is different from the list 2,1,2, because for lists, order matters.
But, as multisets, we want to consider them equal, we only care about the number of 1s and 2s, not their order.

So, we define an equivalence relation on lists, where two lists are considered equivalent if one is a permutation of the other.
That is, if either list can be obtained by reordering the elements of the other list.

Then, MultiSet is defined as the quotient of lists through this relation.
So multisets are equivalence classes of lists.

Most importantly, we cannot represent multisets as polynomial functors.


======


Actually, the constructions are performed not on polynomial functors, but on *quotients* of polynomial functors
